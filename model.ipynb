{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.Data import Dataset, Audio\n",
    "import os\n",
    "from tqdm import tqdm as tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import kurtosis, skew\n",
    "from package.Kernels import DWT\n",
    "\n",
    "dwt = DWT(wavelets =  ['db1','db6','db8','db10'], levels =  10, featureFunctions = \n",
    "    {\n",
    "        'minabs' : lambda x: max(abs(x)),\n",
    "        'min' : min,\n",
    "        'minabs': lambda x: min(abs(x)),\n",
    "        'std': np.std,\n",
    "        'stdabs':  lambda x: np.std(abs(x)),\n",
    "        'mean': np.mean,\n",
    "        'meanabs' : lambda x: np.mean(abs(x)) ,\n",
    "        'median' : np.median ,\n",
    "        'medianabs' : lambda x: np.median(abs(x)),\n",
    "        'kurt' : kurtosis,\n",
    "        'kurtabs' : lambda x: kurtosis(abs(x)),\n",
    "        'skew' : skew,\n",
    "        'skewabs' : lambda x: skew(abs(x)),\n",
    "        'zcr' : lambda x: (np.diff(np.sign(x)) != 0).sum() - (x == 0).sum(),\n",
    "        'energy' : lambda x: np.sum(x.astype(float)**2),\n",
    "    }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/604 [00:00<?, ?it/s]/opt/anaconda3/envs/ser/lib/python3.9/site-packages/scipy/stats/stats.py:959: RuntimeWarning: overflow encountered in square\n",
      "  s = s**2\n",
      "/opt/anaconda3/envs/ser/lib/python3.9/site-packages/scipy/stats/stats.py:961: RuntimeWarning: overflow encountered in multiply\n",
      "  s *= a_zero_mean\n",
      "/opt/anaconda3/envs/ser/lib/python3.9/site-packages/numpy/core/_methods.py:178: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/opt/anaconda3/envs/ser/lib/python3.9/site-packages/numpy/core/_methods.py:178: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "  0%|          | 2/604 [00:00<04:09,  2.41it/s]/Users/agustinrestrepo/Documents/Projects/EmotionSystem/package/Data.py:40: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  wavfile.read(filename)\n",
      "100%|██████████| 604/604 [04:42<00:00,  2.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# Acted Emotional Speech Dynamic Database\n",
    "audioPaths = []\n",
    "for emotion in ['fear', 'sadness', 'happiness', 'anger', 'disgust']:\n",
    "    path = 'SERDatasets.nosync/Acted Emotional Speech Dynamic Database'\n",
    "    for filename in os.listdir(f'{path}/{emotion}'):\n",
    "        if filename.endswith('.wav'):\n",
    "            audioPaths.append((emotion, f'{path}/{emotion}/{filename}'))   \n",
    "\n",
    "# Reading WAV files\n",
    "features = []\n",
    "labels = []\n",
    "for emotion, path in tqdm(audioPaths):\n",
    "    rawAudio = Audio(path)\n",
    "    rawAudio.resample(2**14)\n",
    "    windowedAudios = rawAudio.window(2**14, overlap = 0.6)\n",
    "    features += [dwt.decompose(audio) for audio in windowedAudios]\n",
    "    labels += [emotion]* len(windowedAudios)\n",
    "\n",
    "dataset = Dataset(pd.DataFrame(features, columns = dwt.featureNames()), y= labels)\n",
    "dataset.save(path.split('/')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 936/936 [09:30<00:00,  1.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# CaFE_48k\n",
    "audioPaths = []\n",
    "for emotion in ['Coläre/Faible', 'Coläre/Fort', 'DÇgoñt/Faible', 'DÇgoñt/Fort',  'Joie/Faible', \n",
    "    'Joie/Fort',  'Neutre',   'Peur/Faible', 'Peur/Fort', 'Surprise/Faible', \n",
    "    'Surprise/Fort', 'Tristesse/Faible', 'Tristesse/Fort']:\n",
    "    path = 'SERDatasets.nosync/CaFE_48k'\n",
    "    for filename in os.listdir(f'{path}/{emotion}'):\n",
    "        if filename.endswith('.wav'):\n",
    "            audioPaths.append((emotion.split('/')[0], f'{path}/{emotion}/{filename}'))   \n",
    "\n",
    "# Reading WAV files\n",
    "features = []\n",
    "labels = []\n",
    "for emotion, path in tqdm(audioPaths):\n",
    "    rawAudio = Audio(path)\n",
    "    rawAudio.resample(2**14)\n",
    "    windowedAudios = rawAudio.window(2**14, overlap = 0.6)\n",
    "    features += [dwt.decompose(audio) for audio in windowedAudios]\n",
    "    labels += [emotion]* len(windowedAudios)\n",
    "\n",
    "dataset = Dataset(pd.DataFrame(features, columns = dwt.featureNames()), y= labels)\n",
    "dataset.save(path.split('/')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [02:37<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# emoSynth-DB\n",
    "path = 'SERDatasets.nosync/emoSynth-DB/all_data'\n",
    "labels_csv = pd.read_csv(f'{path}/audio_labels.csv', index_col=1)\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "for filename in tqdm(os.listdir(path+'/wavs')):\n",
    "    rawAudio = Audio(f'{path}/wavs/{filename}')\n",
    "    rawAudio.resample(2**14)\n",
    "    windowedAudios = rawAudio.window(2**14, overlap = 0.6)\n",
    "    features += [dwt.decompose(audio) for audio in windowedAudios]\n",
    "    labels += [[labels_csv.loc[filename]['valence'],labels_csv.loc[filename]['arousal']]]*len(windowedAudios)\n",
    "\n",
    "dataset = Dataset(pd.DataFrame(features, columns = dwt.featureNames()), y= pd.DataFrame(labels, columns=['valence', 'arousal']))\n",
    "dataset.save(path.split('/')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3850/35000 [21:36<2:22:42,  3.64it/s] /Users/agustinrestrepo/Documents/Projects/EmotionSystem/package/Data.py:40: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  wavfile.read(filename)\n",
      "100%|██████████| 35000/35000 [2:49:40<00:00,  3.44it/s]  \n"
     ]
    }
   ],
   "source": [
    "# Emotioanl Speech Database (ESD)\n",
    "path = 'SERDatasets.nosync/Emotional Speech Dataset (ESD)'\n",
    "audioPaths = []\n",
    "for speaker in os.listdir(path):\n",
    "    if not speaker.startswith('00'):\n",
    "        continue\n",
    "    for emotion in ['Angry', 'Happy', 'Neutral', 'Sad', 'Surprise']:\n",
    "        for set_ in ['train', 'test','evaluation']:\n",
    "            for filename in os.listdir(f'{path}/{speaker}/{emotion}/{set_}'):\n",
    "                if filename.endswith('.wav'):\n",
    "                    audioPaths.append((emotion, f'{path}/{speaker}/{emotion}/{set_}/{filename}'))\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "for emotion, path in tqdm(audioPaths):\n",
    "    rawAudio = Audio(path)\n",
    "    rawAudio.resample(2**14)\n",
    "    windowedAudios = rawAudio.window(2**14, overlap = 0.6)\n",
    "    features += [dwt.decompose(audio) for audio in windowedAudios]\n",
    "    labels += [emotion]* len(windowedAudios)\n",
    "\n",
    "#Save features and labels with index number\n",
    "np.savetxt('.dataset/Emotional Speech Dataset (ESD)/features.csv', np.array(features), delimiter=',')\n",
    "pd.DataFrame(labels).to_csv('.dataset/Emotional Speech Dataset (ESD)/labels.csv')\n",
    "\n",
    "dataset = Dataset(pd.DataFrame(features, columns = dwt.featureNames()), y= labels)\n",
    "dataset.save(path.split('/')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rab\n",
      "dis\n",
      "rab\n",
      "rab\n",
      "dis\n",
      "sor\n",
      "sor\n",
      "rab\n",
      "dis\n",
      "pau\n",
      "gio\n",
      "gio\n",
      "dis\n",
      "dis\n",
      "sor\n",
      "dis\n",
      "neu\n",
      "pau\n",
      "gio\n",
      "tri\n",
      "pau\n",
      "dis\n",
      "dis\n",
      "sor\n",
      "sor\n",
      "sor\n",
      "dis\n",
      "neu\n",
      "gio\n",
      "tri\n",
      "dis\n",
      "sor\n",
      "sor\n",
      "sor\n",
      "neu\n",
      "pau\n",
      "tri\n",
      "tri\n",
      "neu\n",
      "sor\n",
      "dis\n",
      "gio\n",
      "pau\n",
      "gio\n",
      "pau\n",
      "gio\n",
      "pau\n",
      "dis\n",
      "rab\n",
      "dis\n",
      "neu\n",
      "pau\n",
      "tri\n",
      "gio\n",
      "gio\n",
      "tri\n",
      "pau\n",
      "gio\n",
      "pau\n",
      "neu\n",
      "rab\n",
      "sor\n",
      "dis\n",
      "neu\n",
      "gio\n",
      "tri\n",
      "tri\n",
      "tri\n",
      "gio\n",
      "neu\n",
      "neu\n",
      "sor\n",
      "sor\n",
      "neu\n",
      "tri\n",
      "pau\n",
      "tri\n",
      "tri\n",
      "pau\n",
      "neu\n",
      "neu\n",
      "sor\n",
      "rab\n",
      "gio\n",
      "pau\n",
      "rab\n",
      "rab\n",
      "rab\n",
      "gio\n",
      "pau\n",
      "rab\n",
      "rab\n",
      "tri\n",
      "neu\n",
      "rab\n",
      "tri\n",
      "neu\n",
      "rab\n",
      "pau\n",
      "gio\n",
      "dis\n",
      "dis\n",
      "dis\n",
      "gio\n",
      "pau\n",
      "gio\n",
      "neu\n",
      "dis\n",
      "sor\n",
      "sor\n",
      "dis\n",
      "dis\n",
      "pau\n",
      "tri\n",
      "gio\n",
      "neu\n",
      "dis\n",
      "sor\n",
      "sor\n",
      "sor\n",
      "dis\n",
      "tri\n",
      "tri\n",
      "pau\n",
      "neu\n",
      "sor\n",
      "sor\n",
      "sor\n",
      "neu\n",
      "tri\n",
      "rab\n",
      "dis\n",
      "rab\n",
      "dis\n",
      "rab\n",
      "sor\n",
      "rab\n",
      "sor\n",
      "rab\n",
      "rab\n",
      "rab\n",
      "gio\n",
      "pau\n",
      "rab\n",
      "rab\n",
      "rab\n",
      "gio\n",
      "pau\n",
      "tri\n",
      "neu\n",
      "tri\n",
      "rab\n",
      "rab\n",
      "neu\n",
      "pau\n",
      "gio\n",
      "dis\n",
      "rab\n",
      "dis\n",
      "gio\n",
      "pau\n",
      "gio\n",
      "pau\n",
      "tri\n",
      "gio\n",
      "pau\n",
      "neu\n",
      "dis\n",
      "sor\n",
      "rab\n",
      "neu\n",
      "gio\n",
      "pau\n",
      "gio\n",
      "tri\n",
      "pau\n",
      "tri\n",
      "gio\n",
      "tri\n",
      "neu\n",
      "dis\n",
      "sor\n",
      "neu\n",
      "neu\n",
      "tri\n",
      "gio\n",
      "tri\n",
      "tri\n",
      "pau\n",
      "neu\n",
      "sor\n",
      "sor\n",
      "neu\n",
      "neu\n",
      "pau\n",
      "tri\n",
      "rab\n",
      "rab\n",
      "gio\n",
      "pau\n",
      "rab\n",
      "rab\n",
      "rab\n",
      "gio\n",
      "pau\n",
      "rab\n",
      "rab\n",
      "neu\n",
      "tri\n",
      "rab\n",
      "neu\n",
      "tri\n",
      "rab\n",
      "sor\n",
      "gio\n",
      "pau\n",
      "tri\n",
      "gio\n",
      "pau\n",
      "neu\n",
      "neu\n",
      "pau\n",
      "tri\n",
      "gio\n",
      "dis\n",
      "dis\n",
      "rab\n",
      "gio\n",
      "pau\n",
      "gio\n",
      "pau\n",
      "gio\n",
      "pau\n",
      "dis\n",
      "sor\n",
      "tri\n",
      "pau\n",
      "neu\n",
      "neu\n",
      "neu\n",
      "pau\n",
      "tri\n",
      "tri\n",
      "sor\n",
      "sor\n",
      "tri\n",
      "gio\n",
      "neu\n",
      "neu\n",
      "neu\n",
      "gio\n",
      "tri\n",
      "tri\n",
      "dis\n",
      "dis\n",
      "dis\n",
      "sor\n",
      "tri\n",
      "pau\n",
      "neu\n",
      "pau\n",
      "gio\n",
      "sor\n",
      "dis\n",
      "dis\n",
      "dis\n",
      "gio\n",
      "pau\n",
      "gio\n",
      "dis\n",
      "sor\n",
      "tri\n",
      "neu\n",
      "neu\n",
      "pau\n",
      "tri\n",
      "sor\n",
      "sor\n",
      "dis\n",
      "sor\n",
      "tri\n",
      "neu\n",
      "gio\n",
      "sor\n",
      "sor\n",
      "dis\n",
      "rab\n",
      "dis\n",
      "rab\n",
      "dis\n",
      "rab\n",
      "sor\n",
      "rab\n",
      "sor\n",
      "sor\n",
      "gio\n",
      "tri\n",
      "neu\n",
      "neu\n",
      "neu\n",
      "tri\n",
      "tri\n",
      "gio\n",
      "dis\n",
      "sor\n",
      "pau\n",
      "tri\n",
      "neu\n",
      "neu\n",
      "neu\n",
      "tri\n",
      "pau\n",
      "tri\n",
      "sor\n",
      "rab\n",
      "dis\n",
      "pau\n",
      "gio\n",
      "pau\n",
      "gio\n",
      "pau\n",
      "gio\n",
      "dis\n",
      "rab\n",
      "sor\n",
      "pau\n",
      "gio\n",
      "pau\n",
      "tri\n",
      "gio\n",
      "neu\n",
      "neu\n",
      "gio\n",
      "tri\n",
      "pau\n",
      "dis\n",
      "neu\n",
      "tri\n",
      "rab\n",
      "neu\n",
      "tri\n",
      "rab\n",
      "rab\n",
      "rab\n",
      "pau\n",
      "gio\n",
      "rab\n",
      "rab\n",
      "rab\n",
      "pau\n",
      "gio\n",
      "rab\n",
      "sor\n",
      "sor\n",
      "rab\n",
      "dis\n",
      "rab\n",
      "dis\n",
      "rab\n",
      "rab\n",
      "dis\n",
      "sor\n",
      "tri\n",
      "neu\n",
      "gio\n",
      "sor\n",
      "sor\n",
      "dis\n",
      "sor\n",
      "tri\n",
      "neu\n",
      "neu\n",
      "tri\n",
      "pau\n",
      "sor\n",
      "sor\n",
      "dis\n",
      "dis\n",
      "gio\n",
      "gio\n",
      "pau\n",
      "dis\n",
      "dis\n",
      "dis\n",
      "sor\n",
      "pau\n",
      "tri\n",
      "neu\n",
      "gio\n",
      "pau\n",
      "sor\n",
      "dis\n",
      "rab\n",
      "sor\n",
      "sor\n",
      "rab\n",
      "rab\n",
      "dis\n",
      "rab\n",
      "dis\n",
      "pau\n",
      "tri\n",
      "neu\n",
      "sor\n",
      "sor\n",
      "sor\n",
      "neu\n",
      "tri\n",
      "gio\n",
      "neu\n",
      "dis\n",
      "sor\n",
      "sor\n",
      "sor\n",
      "dis\n",
      "tri\n",
      "gio\n",
      "pau\n",
      "neu\n",
      "dis\n",
      "sor\n",
      "sor\n",
      "dis\n",
      "dis\n",
      "tri\n",
      "pau\n",
      "gio\n",
      "pau\n",
      "dis\n",
      "dis\n",
      "dis\n",
      "gio\n",
      "tri\n",
      "pau\n",
      "tri\n",
      "neu\n",
      "sor\n",
      "sor\n",
      "neu\n",
      "neu\n",
      "tri\n",
      "pau\n",
      "tri\n",
      "gio\n",
      "tri\n",
      "neu\n",
      "dis\n",
      "sor\n",
      "neu\n",
      "neu\n",
      "gio\n",
      "tri\n",
      "pau\n",
      "gio\n",
      "tri\n",
      "neu\n",
      "dis\n",
      "sor\n",
      "rab\n",
      "neu\n",
      "tri\n",
      "pau\n",
      "gio\n",
      "pau\n",
      "gio\n",
      "gio\n",
      "pau\n",
      "dis\n",
      "dis\n",
      "rab\n",
      "pau\n",
      "gio\n",
      "pau\n",
      "gio\n",
      "tri\n",
      "rab\n",
      "rab\n",
      "neu\n",
      "tri\n",
      "neu\n",
      "rab\n",
      "rab\n",
      "rab\n",
      "pau\n",
      "gio\n",
      "rab\n",
      "rab\n",
      "rab\n",
      "pau\n",
      "gio\n",
      "sor\n",
      "sor\n",
      "neu\n",
      "tri\n",
      "pau\n",
      "tri\n",
      "neu\n",
      "sor\n",
      "sor\n",
      "sor\n",
      "dis\n",
      "neu\n",
      "gio\n",
      "tri\n",
      "dis\n",
      "sor\n",
      "sor\n",
      "dis\n",
      "neu\n",
      "gio\n",
      "pau\n",
      "pau\n",
      "tri\n",
      "dis\n",
      "dis\n",
      "sor\n",
      "dis\n",
      "gio\n",
      "pau\n",
      "gio\n",
      "dis\n",
      "dis\n",
      "sor\n",
      "rab\n",
      "sor\n",
      "rab\n",
      "dis\n",
      "rab\n",
      "rab\n",
      "dis\n",
      "rab\n",
      "tri\n",
      "neu\n",
      "rab\n",
      "tri\n",
      "neu\n",
      "rab\n",
      "pau\n",
      "gio\n",
      "rab\n",
      "rab\n",
      "rab\n",
      "pau\n",
      "gio\n",
      "rab\n",
      "rab\n",
      "sor\n",
      "neu\n",
      "tri\n",
      "tri\n",
      "pau\n",
      "pau\n",
      "tri\n",
      "neu\n",
      "neu\n",
      "sor\n",
      "dis\n",
      "neu\n",
      "tri\n",
      "tri\n",
      "gio\n",
      "gio\n",
      "tri\n",
      "neu\n",
      "neu\n",
      "sor\n",
      "dis\n",
      "neu\n",
      "gio\n",
      "tri\n",
      "pau\n",
      "pau\n",
      "gio\n",
      "tri\n",
      "pau\n",
      "gio\n",
      "neu\n",
      "rab\n",
      "sor\n",
      "dis\n",
      "pau\n",
      "gio\n",
      "pau\n",
      "gio\n",
      "pau\n",
      "gio\n",
      "rab\n",
      "dis\n"
     ]
    }
   ],
   "source": [
    "# EMOVO\n",
    "path = 'SERDatasets.nosync/EMOVO'\n",
    "audioPaths = []\n",
    "for folder in os.listdir(path):\n",
    "    if folder == 'documents':\n",
    "        continue\n",
    "    for filename in os.listdir(f'{path}/{folder}'):\n",
    "        if filename.endswith('.wav'):\n",
    "            emotion = filename[:3]\n",
    "            print(emotion)\n",
    "            audioPaths.append((emotion, f'{path}/{folder}/{filename}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2ea2e0d887f8bed35c356d07d3857655df6955ab94c94cd1eedcb7021ef92be"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
